{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Robbuffet","text":"<p>Conformal prediction + robust decision making with PyTorch predictors and CVXPY optimizers.</p> <p>What it does - Split conformal calibration with geometry-aware scores (L2, L1, Linf, Mahalanobis). - Prediction regions (balls, ellipsoids, unions) that can be sampled, visualized, and used in downstream optimization. - Deterministic robust counterparts for affine uncertainty, scenario-based robust optimization, and gradient-based (Danskin) solvers for unions.</p> <p>Install - <code>pip install robbuffet</code> (Python 3.10+). For development: <code>pip install -e .[dev]</code>.</p> <p>Getting started - Read the Quickstart. - Browse runnable Examples. - See API for core classes.</p>"},{"location":"api/","title":"API Overview","text":""},{"location":"api/#calibration","title":"Calibration","text":"<ul> <li><code>SplitConformalCalibrator(predictor, score_fn, calibration_data, device=None)</code></li> <li><code>calibrate(alpha: float) -&gt; float</code>: fit quantile.</li> <li><code>predict_region(x: torch.Tensor) -&gt; PredictionRegion</code></li> </ul>"},{"location":"api/#scores","title":"Scores","text":"<ul> <li><code>L2Score</code>, <code>L1Score</code>, <code>LinfScore</code>, <code>MahalanobisScore(weight)</code></li> <li><code>score(prediction, target) -&gt; torch.Tensor</code></li> <li><code>build_region(prediction, quantile) -&gt; PredictionRegion</code></li> </ul>"},{"location":"api/#regions","title":"Regions","text":"<ul> <li>Classes: <code>L2BallRegion</code>, <code>L1BallRegion</code>, <code>LinfBallRegion</code>, <code>EllipsoidRegion</code>, <code>UnionRegion</code></li> <li>Methods: <code>sample(n)</code>, <code>contains(y)</code>, <code>cvxpy_constraints(var)</code> (convex sets only), <code>is_convex()</code></li> <li>For unions, use support functions (<code>support_function</code>) or scenario-based optimization; no single convex constraint is provided.</li> </ul>"},{"location":"api/#robust-optimization-helpers","title":"Robust optimization helpers","text":"<ul> <li><code>region.support_function(direction)</code>: support of a region (unions take max of component supports).</li> <li><code>robustify_affine_objective(base_obj, theta_direction, region)</code>: add worst-case linear term.</li> <li><code>robustify_affine_leq(theta_direction, rhs, region)</code>: robust linear inequality.</li> <li><code>ScenarioRobustOptimizer(decision_shape, objective_fn, constraints_fn=None, num_samples=128, seed=None)</code></li> <li><code>build_problem(region, solver=None) -&gt; cp.Problem</code></li> <li><code>AffineRobustSolver(decision_shape, region, base_objective_fn, theta_direction_fn=None, constraints_fn=None, robust_constraints_fn=None, solver=None)</code></li> <li><code>solve() -&gt; (w*, status)</code>; assumes affine dependence on uncertainty (objective term and optional affine constraints).</li> <li><code>DanskinRobustOptimizer(region, nom_obj, value_and_grad_fn=None, torch_value_fn=None, project_fn=None, solver=\"ECOS\")</code></li> <li><code>solve(w0, step_size=..., max_iters=..., tol=..., verbose=False) -&gt; (w*, history)</code></li> <li>Either provide <code>value_and_grad_fn</code> (returns value, grad_w) or a PyTorch scalar <code>torch_value_fn(w_tensor, theta_tensor)</code> for autograd-based gradients.</li> </ul>"},{"location":"api/#metrics","title":"Metrics","text":"<ul> <li>Regions expose <code>volume</code> (analytic where available) and <code>volume_mc(bounds, num_samples=...)</code> for Monte Carlo estimation.</li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#011","title":"0.1.1","text":"<ul> <li>Version bump for latest PyPI release and refreshed license metadata.</li> </ul>"},{"location":"changelog/#001","title":"0.0.1","text":"<ul> <li>Initial scaffold: split conformal calibration, geometry-aware regions, deterministic and scenario robust helpers, examples, and CI.</li> </ul>"},{"location":"concepts/","title":"Conformal Scores and Regions","text":""},{"location":"concepts/#residual-based-scores","title":"Residual-based scores","text":"<ul> <li>L2Score: \\(s(x,y) = \\|f(x) - y\\|_2\\) \u2192 L2 ball.</li> <li>L1Score: \\(s(x,y) = \\|f(x) - y\\|_1\\) \u2192 L1 ball.</li> <li>LinfScore: \\(s(x,y) = \\|f(x) - y\\|_\\infty\\) \u2192 Linf ball.</li> <li>MahalanobisScore: \\(s(x,y) = \\sqrt{(f(x)-y)^\\top W (f(x)-y)}\\) \u2192 ellipsoid.</li> </ul>"},{"location":"concepts/#gpcpscore-union-of-balls","title":"GPCPScore (union of balls)","text":"<ul> <li>Score: \\(s(x,y) = \\min_{k} \\| \\text{sample}_k(x) - y \\|_2\\).</li> <li>Predictor returns K samples; prediction region becomes a union of L2 balls centered at the samples with radius equal to the conformal quantile.</li> <li>Useful with generative models that can sample conditional outputs.</li> </ul>"},{"location":"concepts/#calibrators","title":"Calibrators","text":"<ul> <li>SplitConformalCalibrator runs split conformal quantile estimation given a predictor and score.</li> <li>For GPCPScore, predictor should return samples (shape K x batch x d); the score builds the union region.</li> </ul>"},{"location":"concepts/#robust-optimization-paths","title":"Robust optimization paths","text":"<ul> <li>Deterministic (affine in uncertainty): use <code>robustify_affine_objective</code> / <code>robustify_affine_leq</code> with <code>region.support_function</code> (unions use max of component supports).</li> <li>Scenario-based: <code>ScenarioRobustOptimizer</code> samples from regions (works for unions).</li> <li>Gradient-based Danskin: <code>DanskinRobustOptimizer</code> solves inner maximization per component (works for unions) and updates w via gradients (optionally autograd).</li> <li>Example (capacity planning): \\(\\min_{0 \\le c \\le \\bar{c}} \\max_{\\lambda \\in \\mathcal{C}(x)} c_{\\text{cap}} c + c_{\\text{short}} (\\lambda - \\mu c)^+\\) with \\(\\mathcal{C}(x)\\) an L2 interval.</li> </ul>"},{"location":"concepts/#region-volume","title":"Region volume","text":"<ul> <li>Regions provide <code>volume</code> when closed-form (L2/L1/Linf balls, ellipsoids); unions return None.</li> <li>Use <code>region.volume_mc(bounds)</code> to estimate volume for unions or complex regions.</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Please open issues for bugs/feature requests and PRs for fixes/additions. See CONTRIBUTING.md in the repo for full guidelines.</p> <p>Quick start: <pre><code>pip install -e .[dev]\npytest\n</code></pre></p>"},{"location":"examples/","title":"Examples","text":"<p>Run any script with <code>python examples/&lt;script&gt;.py</code>.</p> <ul> <li><code>robust_shortest_path_metrla.py</code>: Conformalized DCRNN_PyTorch forecasts + robust shortest path on METR-LA (requires the <code>examples/DCRNN_PyTorch</code> submodule and its precomputed predictions NPZ).</li> <li><code>robust_bike_newsvendor.py</code>: Conformal calibration on UCI Bike Sharing data + robust newsvendor decisions vs nominal.</li> <li><code>robust_capacity_planning.py</code>: Synthetic arrival forecasting + robust server capacity sizing with conformal intervals.</li> <li><code>robust_fractional_knapsack.py</code>: SBIBM simulator + flow-based posterior samples for robust fractional knapsack.</li> </ul>"},{"location":"examples/#math-formulations","title":"Math formulations","text":"<p>Bike newsvendor</p> <ul> <li>Region: \\(\\mathcal{C}(x) = \\{c : \\|c - \\hat{y}(x)\\|_2 \\le q\\}\\)</li> <li>Objective: \\(\\min_{q \\ge 0} \\max_{c \\in \\mathcal{C}(x)} \\; c_u (c - q)^+ + c_o (q - c)^+.\\)</li> </ul> <p>METR-LA shortest path</p> <ul> <li>Region: \\(\\mathcal{C}(x) = \\bigcup_{k} \\{c : \\|c - \\hat{c}_k\\|_2 \\le q\\}\\)</li> <li>Objective: \\(\\min_{w} \\max_{c \\in \\mathcal{C}(x)} \\langle c, w\\rangle \\quad \\text{s.t. } A w = b,\\; 0 \\le w \\le 1.\\)</li> </ul> <p>Fractional knapsack (SBIBM)</p> <ul> <li>Region: \\(\\mathcal{C}(x) = \\bigcup_k \\{v : \\|v - \\hat{v}_k\\|_2 \\le q\\}\\) (weights fixed to nominal proxy).</li> <li>Objective: \\(\\max_{x} \\; \\langle v, x\\rangle \\quad \\text{s.t. } \\langle w, x\\rangle \\le B,\\; 0 \\le x \\le 1\\), with robust variant using worst-case \\(v\\).</li> </ul> <p>Capacity planning (synthetic arrivals)</p> <ul> <li>Region: \\(\\mathcal{C}(x) = \\{ \\lambda : |\\lambda - \\hat{\\lambda}(x)| \\le q\\}\\) (L2 interval around predicted arrival rate).</li> <li>Objective: \\(\\min_{0 \\le c \\le \\bar{c}} \\; \\max_{\\lambda \\in \\mathcal{C}(x)} \\; c_{\\text{cap}} \\, c + c_{\\text{short}} \\, (\\lambda - \\mu c)^+\\), where \\(c\\) is capacity (servers), \\(\\mu\\) is service rate, and \\(c_{\\text{cap}}, c_{\\text{short}}\\) are cost coefficients. Inner max is approximated by sampling from \\(\\mathcal{C}(x)\\).</li> </ul>"},{"location":"examples/#empirical-results-10-trials","title":"Empirical results (10 trials)","text":""},{"location":"examples/#newsvendor-bike-sharing","title":"Newsvendor (Bike Sharing)","text":"method mean objective std paired t-test (robust &lt; nominal) robust 2560.51 24.30 t = -90.94, p = 5.958e-15 nominal 4370.20 83.10 \u2013"},{"location":"examples/#shortest-path-metr-la","title":"Shortest path (METR-LA)","text":"method mean objective std paired t-test (robust &lt; nominal) robust 109.58 15.56 t = -9.52, p = 2.682e-06 nominal 12112.04 3780.02 \u2013"},{"location":"examples/#capacity-planning","title":"Capacity planning","text":"method mean objective std paired t-test (robust &lt; nominal) robust 8.0131 1.0061 t = -28.7643, p = 1.807e-10 nominal 45.9437 4.2929 \u2013"},{"location":"publishing/","title":"Publishing to PyPI","text":"<ol> <li>Bump the version in <code>pyproject.toml</code> and add a changelog entry.</li> <li>Build artifacts from a clean environment:    <pre><code>python -m pip install --upgrade build twine\npython -m build\n# dist/ now contains robbuffet-&lt;ver&gt;.tar.gz and robbuffet-&lt;ver&gt;-py3-none-any.whl\n</code></pre></li> <li>Upload with a PyPI token:    <pre><code>export PYPI_TOKEN=\"pypi-XXXXXXXXXXXXXXXXXXXX\"\ntwine upload -u __token__ -p \"$PYPI_TOKEN\" dist/*\n</code></pre></li> <li>Verify the release:    <pre><code>pip install --no-cache-dir robbuffet==&lt;ver&gt;\npython - &lt;&lt;'PY'\nimport robbuffet\nprint(robbuffet.__version__)\nPY\n</code></pre></li> </ol> <p>For TestPyPI, replace the upload command with: <pre><code>twine upload --repository testpypi dist/*\n</code></pre></p>"},{"location":"quickstart/","title":"Quickstart","text":""},{"location":"quickstart/#install","title":"Install","text":"<pre><code>pip install robbuffet\n</code></pre> <p>For development (tests, build, publishing): <pre><code>pip install -e .[dev]\n</code></pre></p>"},{"location":"quickstart/#quickstart-split-conformal-l2-residual-score","title":"Quickstart (split conformal, L2 residual score)","text":"<pre><code>import torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom robbuffet import L2Score, SplitConformalCalibrator\n\n# toy predictor\nmodel = torch.nn.Linear(2, 2)\n\n# calibration data loader\ntorch.manual_seed(0)\nx_cal = torch.randn(200, 2)\ny_cal = x_cal + 0.1 * torch.randn_like(x_cal)\ncal_loader = DataLoader(TensorDataset(x_cal, y_cal), batch_size=32)\n\ncal = SplitConformalCalibrator(model, L2Score(), cal_loader)\nalpha = 0.1\ncal.calibrate(alpha=alpha)\n\nx_new = torch.randn(1, 2)\nregion = cal.predict_region(x_new)\nprint(\"center:\", region.center, \"radius:\", region.radius)\n</code></pre>"},{"location":"quickstart/#visualization","title":"Visualization","text":"<pre><code>from robbuffet import vis\nimport matplotlib.pyplot as plt\nvis.plot_region_2d(region, grid_limits=((-1, 1), (-1, 1)), resolution=200)\nplt.show()\n</code></pre>"},{"location":"quickstart/#affine-robust-solver","title":"Affine Robust Solver","text":"<p>For linear/affine dependence on the uncertain parameter <code>theta</code>, build a predictor + score and conformal region, then use support functions: <pre><code>import cvxpy as cp\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom robbuffet import L2Score, SplitConformalCalibrator, AffineRobustSolver\n\n# toy predictor\nmodel = torch.nn.Linear(2, 2)\ntorch.manual_seed(0)\nx_cal = torch.randn(200, 2)\ny_cal = x_cal + 0.1 * torch.randn_like(x_cal)\ncal_loader = DataLoader(TensorDataset(x_cal, y_cal), batch_size=32)\n\ncal = SplitConformalCalibrator(model, L2Score(), cal_loader)\nq = cal.calibrate(alpha=0.1)\nregion = cal.predict_region(torch.zeros(1, 2))  # example point\n\ndef base_obj(w):\n    return cp.norm(w, 2)\n\ndef theta_dir(w):\n    return w\n\ndef robust_constraints(w):\n    # Example affine constraint &lt;w, theta&gt; &lt;= 0.5 for all theta in region\n    return [(w, 0.5)]\n\nsolver = AffineRobustSolver(\n    decision_shape=(2,),\n    region=region,\n    base_objective_fn=base_obj,\n    theta_direction_fn=theta_dir,\n    constraints_fn=lambda w: [],\n    robust_constraints_fn=robust_constraints,\n)\nw_star, status = solver.solve()\nprint(\"status:\", status, \"w*:\", w_star)\n</code></pre></p> <p><code>AffineRobustSolver</code> assumes the uncertain parameter enters the problem affinely. The robustified optimization has the form:</p> <p>\\(\\min_{w} \\quad g(w) + \\sup_{\\theta \\in \\mathcal{C}(x)} \\langle d(w), \\theta \\rangle\\) \\(\\text{s.t. } h_i(w) \\le 0, \\quad \\langle a_j(w), \\theta \\rangle \\le b_j(w) \\quad\\quad \\forall \\theta \\in \\mathcal{C}(x).\\)</p> <p>Here:  </p> <ul> <li> <p>\\(g(w)\\) is <code>base_objective_fn(w)</code>; \\(h_i(w)\\) and \\(b_j(w)\\) come from <code>constraints_fn</code>.  </p> </li> <li> <p>The dependence on \\(\\theta\\) is affine: <code>theta_direction_fn(w)</code> corresponds to \\(d(w)\\) in the objective, and each pair \\((a_j(w), b_j(w))\\) comes from <code>robust_constraints_fn</code>.  </p> </li> <li> <p>\\(\\mathcal{C}(x)\\) is the conformal region returned by <code>cal.predict_region(...)</code>.  </p> </li> </ul> <p><code>AffineRobustSolver</code> replaces the affine \\(\\theta\\) terms with support functions \\(h_{\\mathcal{C}}(\\cdot)\\); non-affine \\(\\theta\\) dependence is not supported. Use the Danskin or sampling-based approaches when the uncertainty enters non-affinely or the region is nonconvex/union and you prefer gradient-based optimization.</p>"},{"location":"quickstart/#gradient-based-danskin-solver","title":"Gradient-Based (Danskin) Solver","text":"<p>For nonconvex or union regions, get a conformal region from a predictor/score, then use the Danskin optimizer: <pre><code>import numpy as np\nimport torch\nfrom robbuffet import DanskinRobustOptimizer, SplitConformalCalibrator\nfrom robbuffet.scores import GPCPScore\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# toy sampler predictor: returns K samples (K, batch, d)\ndef sampler(x):\n    base = torch.randn(5, x.shape[0], 2)\n    return base\n\nscore_fn = GPCPScore(sampler)\ncal = SplitConformalCalibrator(sampler, score_fn, DataLoader(TensorDataset(torch.zeros(10, 1), torch.zeros(10, 1)), batch_size=2))\nq = cal.calibrate(alpha=0.1)\nregion = cal.predict_region(torch.zeros(1, 1))\n\ndef inner(theta_var, w_np):\n    return theta_var @ w_np\n\ndef value_and_grad(w_np, theta_np):\n    return float(theta_np @ w_np), np.array(theta_np, dtype=float)\n\nproject = lambda w_vec: np.clip(w_vec, -1, 1)\nopt = DanskinRobustOptimizer(region, nom_obj=inner, value_and_grad_fn=value_and_grad, project_fn=project)\nw_star, _ = opt.solve(w0=np.zeros(2), step_size=0.1, max_iters=100)\nprint(\"Danskin w*:\", w_star)\n</code></pre></p>"}]}